---
title: "Final Project - R programming - Prof. Kang Lele"
author: "Do Minh Ngoc - 502024145013"
date: "2025-07-18"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# 1. Final Project Description
### 1.1. Introduction

Ethereum, launched in 2015, is a decentralized blockchain enabling smart contracts and DApps with its native currency, Ether (ETH). It has become the most popular blockchain, driving decentralized finance (DeFi) and non-fungible tokens (NFTs), with ETH ranking second in market cap. Traditional models like ARIMA focus on linear patterns and Bitcoin, while AI models such as ANN fail to incorporate economic and technological factors impacting exchange rates. This study combines economic and technological factors with LSTM networks to predict Ethereum exchange rates more effectively.

### 1.2. Research Question
- Can economic and technological factors improve Ethereum exchange rate prediction compared to historical data alone?
- Which factors significantly affect Ethereum exchange rates?
- Which machine learning model (LSTM, SVR, ARIMA) is most accurate?

### 1.3. Research Method
A two-stage approach is used: Random Forest and ANN for feature selection. Phase 2: LSTM (selected features) for prediction, compared to traditional models (SVR, ARIMA, LSTM (old price))).


### Import Essential Packages

```{r packages, echo=TRUE, message=FALSE, warning=FALSE}
library('tidyr')
library('ggplot2')
library('stringr')
library('skimr')
library('readr')
library('dplyr')
library('zoo')
library('caret')
library(randomForest)
library(nnet)
library(forecast)
library(e1071)
library(gridExtra)
```


# 2. The data
### Data Preparation

##### Table 1. List of economic and technological factors that can affect **ETH price**
| **Description**                           | **Previous Research**                                  |
|-------------------------------------------|--------------------------------------------------------|
| **Economic Factor**                       |                                                        |
| - Crude oil price                         | Gospodinov & Jamali, 2015                              |
| - Gold price                              | Gospodinov & Jamali, 2015                              |
| - NASDAQ                                   | Gospodinov & Jamali, 2015                              |
| - Global currency ratio (USD)            | Dyhrberg, 2015; Jang & Lee, 2018; Kristjanpoller & Minutolo, 2018 |
| - EUR/USD, JPY/USD, CNY/USD               | Dyhrberg, 2015; Jang & Lee, 2018; Kristjanpoller & Minutolo, 2018 |
| **Technology Factor**                     |                                                        |
| - gas limit                               | Gospodinov & Jamali, 2015                              |
| - Bitcoin price                           | Saad et al. (2019)                                     |
| - Blocksize                               | W. Chen, H. Xu, L. Jia et al (2021)                    |
| - Blocktime                               | W. Chen, H. Xu, L. Jia et al (2021)                    |
| - Transaction Fee                          | W. Chen, H. Xu, L. Jia et al (2021)                    |
| - Transaction volume                       | W. Chen, H. Xu, L. Jia et al (2021)                    |
| - Transaction Value                        | W. Chen, H. Xu, L. Jia et al (2021)                    |
| - Market capitalization                   | W. Chen, H. Xu, L. Jia et al (2021)                    |
| - Public Attention (Volume of Tweets on Twitter) | Dastgir, Demir, Downing, Gozgor, & Chi, 2018; Polasik et al., 2015; Zhang, Wang, Li, & Shen, 2018 |
| **Source**                                | Synthesis of previous studies                          |

### 2.1. Technical and Blockchain Data (bitinfocharts.com)
Data from [bitinfocharts.com](https://bitinfocharts.com) and [ethereumscan.io](https://etherscan.io/) provides detailed historical data on various aspects of the Ethereum blockchain, including:

- **Price of Ethereum**: The ETH/USD price shows how much one Ethereum (ETH) is worth in US dollars.
- **Ethereum Mention Tweets**: Measures how often Ethereum is mentioned on Twitter, showing the number of tweets containing Ethereum-related keywords.
- **Transaction Value**: Total value of transactions processed on the Ethereum network, expressed in USD or ETH.
- **Number of Transactions**: The total number of transactions recorded on the blockchain during a given period.
- **Average Transaction Fee**: The average fee paid for each transaction.
- **Block Size**: The average size of blocks added to the blockchain.
- **Block Time**: The average time it takes to create a new block.
- **Market Cap**: Ethereum's market capitalization.
- **Gas Limit** refers to the maximum amount of computational work or resources that can be used for a transaction or contract execution on the Ethereum network. It determines how much "gas" (a measure of computational effort) is allowed for a transaction or smart contract. A higher gas limit allows for more complex transactions or contracts but also increases transaction costs.
- **BTC Price** represents the market value of Bitcoin (BTC), the first and most well-known cryptocurrency. It is typically quoted in terms of USD or other fiat currencies and serves as a key indicator of Bitcoin's value in the broader cryptocurrency market. The BTC price fluctuates based on demand, market sentiment, and external economic factors.


These metrics help assess the health and performance of the Ethereum network, which directly impacts the value of Ether (ETH).

### 2.2. Economic Data (investing.com)
Data from [Investing.com](https://investing.com) includes global market data such as:

- **Exchange Rates**: Data on exchange rates between various currencies (e.g., CNY/USD, EUR/USD, JPY/USD).
- **Gold Price**: The international gold price.
- **Oil Price**: Crude oil prices.
- **Stock Indices**: Stock indices such as the Nasdaq.

These data points reflect macroeconomic conditions and traditional market factors that influence investor sentiment, which in turn impacts the value of digital assets like Ether.

**Note** : Since the data comes from different sources, some use commas (,) to separate decimal numbers, while others use periods (.). This is why the following code is used.

```{r data, echo=TRUE, message=FALSE, warning=FALSE}
#Read csv sep by ;
data <- read_delim(
  "Dataset.csv",
  delim = ";",
  locale = locale(decimal_mark = ",", grouping_mark = ".")
)

data2 <- read_delim(
  "Dataset.csv",
  delim = ";",
  locale = locale(decimal_mark = ".", grouping_mark = ",")
)

data$btc_price <- data2$btc_price

data <- data[-1]

#Overview of data
skim_without_charts(data)

```
The data has many missing values and some columns are mixed between character and numeric types, so it needs to be cleaned.

## 2.3. Data Cleaning

```{r data clean, echo = TRUE, warning =FALSE}
data_clean <- na.omit(data)
data_clean <- as.data.frame(lapply(data_clean, function(x) ifelse(x == "null", NA, x)))
cols_need_converted <- c("tweets","transaction_fee","transaction_value","number_of_transaction","blocksize", "blocktime", "marketcap")
data_clean[cols_need_converted] <- lapply(data_clean[cols_need_converted], function(x) gsub(",", ".", x))
data_clean[cols_need_converted] <- lapply(data_clean[cols_need_converted], as.numeric)
data_clean$date <- as.Date(data_clean$date, format = "%d/%m/%y")

#Forward & Backward fill to fill time series missing value
# Forward fill,then, backward fill 
forward_backward_fill <- function(data_clean, col_name) {
  # Forward fill
  data_clean[[col_name]] <- na.locf(data_clean[[col_name]], na.rm = FALSE)
  
  # Backward fill
  data_clean[[col_name]] <- na.locf(data_clean[[col_name]], fromLast = TRUE, na.rm = FALSE)
  
  return(data_clean)
}

for (i in 1:8) {
  data_clean <- forward_backward_fill(data_clean, colnames(data_clean)[i])
}

skim_without_charts(data_clean)
```

### 2.4. Data Normalization
For the model to work well, the input data must be processed to prevent variables with larger values from dominating those with smaller values, as recommended by Rezakazemi et al. (2013). In other words, scaling the variables ensures that they have equal importance in the model training process.

This study used the **Min-Max normalization** method to "balance" the input variables. The Min-Max normalization formula is:

$$
x_{\text{subscript i}} = \frac{(x_i - \min(X))}{(\max(X) - \min(X))}
$$

This formula "shrinks" all values of a variable to the range of 0 to 1. By doing so, variables with different units of measurement and different magnitudes are treated equally when entered into the model.

```{r data scale, echo = TRUE, message=FALSE, warning=FALSE}
# Create normalize function Min-Max
normalize <- function(x) {
  return((x - min(x)) / (max(x) - min(x)))
}

# Apply for all columns
columns_to_scale <- c('tweets', 'transaction_fee', 'transaction_value', 
                      'number_of_transaction', 'blocksize', 'blocktime', 
                      'marketcap', 'gas_limit', 'cny_usd', 'eur_usd', 
                      'jpy_usd', 'gold', 'Oil', 'Nasdaq','btc_price')

scaled_data <- data_clean
scaled_data[columns_to_scale] <- lapply(scaled_data[columns_to_scale], normalize)

# Check the result
head(scaled_data)

```

### 2.5. Visualization normalized data
```{r data visualization, echo = TRUE, message=FALSE, warning=FALSE, fig.show="hide"}
# List column
columns <- c("tweets", "transaction_fee", "transaction_value", "number_of_transaction", 
             "blocksize", "blocktime", "marketcap", "price", "gas_limit", "cny_usd", 
             "eur_usd", "jpy_usd", "gold", "Oil", "Nasdaq", "btc_price")

# List chart
plots <- list()

# Create chart for each variable
plots <- list()

for (col in columns) {
  p <- ggplot(scaled_data, aes(x = date, y = !!sym(col))) +  
    geom_line(color = "blue") +  
    labs(title = col, x = "Year", y = "Value") +
    ylim(0, 1) +  
    theme_minimal()
  plots[[col]] <- p
}

# Arrange chart
grid.arrange(
  # 8 first charts
  plots[[1]], plots[[2]], plots[[3]], plots[[4]], plots[[5]], plots[[6]], plots[[7]], plots[[8]], 
  # 7 remaining chart
  plots[[9]], plots[[10]], plots[[11]], plots[[12]], plots[[13]], plots[[14]], plots[[15]],
  ncol = 2  
)

```

```{r, echo=FALSE}
# Display the imported image
knitr::include_graphics("/Users/dominhngoc/Desktop/Final R/result.png")
```

# 3. Modeling Stage 1: Feature Selection
### Modeling Stage 1: Feature Selection using Random Forest and ANN

In Stage I, I focused on **feature selection** to identify the most predictive economic and technological factors, removing redundant ones. This stage is broken into three sub-steps:

#### 1. Feature Selection Models
I used two machine learning models, **Random Forest (RF)** and **Artificial Neural Networks (ANN)**, both known for their strong feature-filtering capabilities (Enke & Thawornwong, 2005; Tsai & Hsiao, 2011). These models help identify which features contribute most to predicting Ethereum exchange rates.

#### 2.Factor Importance Assessment
**Sensitivity analysis** was used to evaluate the importance of each factor (Dag et al., 2016). The importance values of the features were then normalized to a scale of 0 to 1.

#### 3.Combining Feature Selection Methods
As suggested by Tsai and Hsiao (2011), combining multiple feature selection techniques improves prediction performance. I employed a "crossover strategy" to filter out unimportant variables, resulting in a final set of candidate features for Stage II of modeling. The **caret package** in R was used to implement the RF models (Kuhn, 2015).

### 3.1. Random Forest (RF)
**Random Forest** is an ensemble learning algorithm that builds multiple decision trees using bootstrap and random node-splitting techniques. Predictions are made by aggregating the "votes" from individual trees. RF is robust against noisy and missing data and can handle complex interactions between categorical variables (Breiman, 2001; Svetnik et al., 2003).

#### Factor Importance in RF
The importance of each factor is calculated using the **Out-Of-Bag Error (OOBE)** method. Two error measures are used to evaluate importance:

1. **OOBE1**: The initial error calculated using the data not used in tree construction.
2. **OOBE2**: The error after adding noise to the factor of interest in the OOB data.

#### Importance Measures
- **%IncMSE (Percentage Increase in Mean Squared Error)**: Measures how much the model's error increases when a variable is removed. A higher %IncMSE indicates greater importance.
- **IncNodePurity (Increase in Node Purity)**: Measures how much a variable reduces node impurity. The higher the IncNodePurity, the more important the variable.

These measures guide the feature selection process, ensuring the most relevant variables are retained for further analysis.

```{r rf 1, echo = TRUE, warning =FALSE}
#Split into train and test dataset
set.seed(123)
train_index <- createDataPartition(scaled_data$price, p = 0.8, list = FALSE)
train_data <- scaled_data[train_index, ]
test_data <- scaled_data[-train_index, ]
train_data <- train_data[, !names(train_data) %in% "date"]
test_data <- test_data[, !names(test_data) %in% "date"]


#Check the size of train and test dataset
dim(train_data)
dim(test_data)
```

```{r rf 2, echo = TRUE, warning =FALSE}
# Feature selection with Random Forest trên train_data
rf_model <- randomForest(price ~ ., data = train_data, importance = TRUE)

# Print important features
print(rf_model)
varImpPlot(rf_model)
```

### 3.2. ANN
Artificial Neural Network (ANN) and Feature Importance Evaluation

**Artificial Neural Networks (ANN)** are computational models inspired by the human brain. They consist of layers of interconnected nodes (neurons) that work together to solve complex problems. ANN models can learn intricate patterns and relationships in data, making them powerful for predictive tasks. The model used in this study is a feedforward network with 10 hidden nodes and a linear output, trained on the `train_data` dataset.

#### Model Training and Prediction
The following code builds and trains an ANN model using the `nnet` package:

```{r ann 1, echo = TRUE, warning =FALSE}
# Build model ANN
ann_model <- nnet(price ~ ., data = train_data, size = 10, linout = TRUE, trace = FALSE)

# Predict
ann_predictions <- predict(ann_model, test_data)

mse_full <- mean((ann_predictions - test_data$price)^2)
cat("MSE of full model: ", mse_full, "\n")
```

Here, the model is trained to predict the price variable using all available features. The Mean Squared Error (MSE) is calculated to assess the model's performance on the test dataset.

**Feature Importance Evaluation**
To assess the importance of each feature in the model, we evaluate the MSE when a feature is removed from the model. A large increase in MSE indicates that the feature is important for accurate predictions.

The following function calculates the MSE when a feature is excluded:

```{r ann 2, echo = TRUE, warning =FALSE}
mse_full <- mean((ann_predictions - test_data$price)^2)
cat("MSE of full model: ", mse_full, "\n")

# Function to re-calculate MSE when remove one feature
calculate_mse <- function(exclude_col) {
  # Remove one feature from train and test data set repetitively
  train_data_mod <- train_data[, !names(train_data) %in% exclude_col]
  test_data_mod <- test_data[, !names(test_data) %in% exclude_col]
  
  # Train model
  ann_model_mod <- nnet(price ~ ., data = train_data_mod, size = 10, linout = TRUE, trace = FALSE)
  
  # Predict
  ann_predictions_mod <- predict(ann_model_mod, test_data_mod)
  
  # Calculate MSE for changed model
  mse_mod <- mean((ann_predictions_mod - test_data_mod$price)^2)
  return(mse_mod)
}

# Apply function to calculate MSE when remove feature
features <- setdiff(names(train_data), "price") #Remove price - dependant variable from features list 
mse_results <- sapply(features, calculate_mse)

# Calculate delta mse
delta_mse <- mse_results - mse_full
cat("Delta MSE for each feature removal: \n")
print(delta_mse)

```

#### We select features based on the following criteria:

* %IncMSE: Features that, when removed, cause the largest increase in MSE. The higher the %IncMSE, the more important the feature is.

* IncNodePurity: Features that, when removed, cause the highest increase in node impurity. The higher the IncNodePurity, the more important the feature is.

* MSE: Features that cause the biggest increase in error (MSE) when removed. The greater the MSE change, the more critical the feature is.

**Conclusion**
The following variables were selected based on their high **%IncMSE**, **IncNodePurity**, and **MSE** values, making them the most important for predicting Ethereum exchange rates:

- **marketcap**
- **gas_limit**
- **eur_usd**
- **btc_price**
- **blocksize**
- **transaction_fee**
- **Nasdaq**
- **cny_usd**

These features will be used as input for the LSTM model.

**Note**: Because there exist lots of limitation when running LSTM in R, I save the csv of selected feature to run by Python seperately and import result in this notebook.

```{r save data, echo = TRUE, warning =FALSE}
selected_features <- c('marketcap', 'gas_limit', 'eur_usd', 'btc_price', 'blocksize', 'transaction_fee', 'Nasdaq', 'cny_usd')

# Train and test data for selected feature
train_data_selected <- train_data[, c(selected_features, 'price')] 
test_data_selected <- test_data[, c(selected_features, 'price')] 

head(train_data_selected)
```


# 4. Modeling Stage 2
### 4.1. SVR & ARIMA (previous price)
**Support Vector Regression (SVR)** is a machine learning algorithm used for regression tasks like predicting Ethereum prices. It handles non-linear data by using kernel functions to map data to a higher-dimensional space and can operate efficiently with high-dimensional data. SVR is also robust to overfitting, helping it generalize well to new data. The **e1071** package in R was used to build and train the SVR model.

**Autoregressive Integrated Moving Average (ARIMA)**
**ARIMA** is a statistical model for time series prediction, combining autoregressive (AR), differencing (I), and moving average (MA) components. It is useful for modeling trends and seasonality in Ethereum price data and predicting future prices. The **forecast** package in R was used to build and train the ARIMA model, which helps capture patterns and forecast future Ethereum prices.

```{r svr arima, echo = TRUE, warning =FALSE}
# Define metric to assess the performance of each model (MAE, MAPE, DA)
rmse <- function(actual, predict) {
  sqrt(mean((predicted - actual)^2, na.rm = TRUE))
}
mae <- function(actual, predicted) {
  mean(abs(predicted - actual), na.rm = TRUE)
}
mape <- function(actual, predicted) {
  mean(abs((predicted - actual) / actual), na.rm = TRUE) * 100
}
directional_accuracy <- function(actual, predicted) {
  actual_diff <- diff(actual)
  pred_diff   <- diff(predicted)
  mean(sign(actual_diff) == sign(pred_diff), na.rm = TRUE) * 100
}

# Initialize result storage
results <- data.frame()

n_iter <- 10
for (i in 1:n_iter) {
  actual <- test_data$price  
  
  # --- ARIMA ---
  arima_model <- auto.arima(train_data$price)
  arima_pred <- forecast(arima_model, h = length(actual))$mean
  
  rmse_arima <- sqrt(mean((arima_pred - actual)^2))
  mae_arima <- mean(abs(arima_pred - actual))
  mape_arima <- mean(abs((arima_pred - actual) / actual)) * 100
  da_arima <- mean(sign(diff(arima_pred)) == sign(diff(actual)), na.rm = TRUE) * 100
  
  results <- rbind(results, data.frame(
    Model = "ARIMA",
    RMSE = rmse_arima,
    MAE = mae_arima,
    MAPE = mape_arima,
    DA = da_arima
  ))
  
  # --- SVR ---
  # Create data train_svr from value lag-1
  train_svr <- data.frame(
    y = train_data$price[-1],  # Objective: next value
    x = train_data$price[-nrow(train_data)]  # Feature: previous price (lag-1)
  )
  
  # Create data test_svr for SVR (lag-1)
  test_svr <- data.frame(
    x = c(tail(train_data$price, 1), test_data$price[-nrow(test_data)])  # Feature for test data set 
  )
  
  # Build SVR Model
  svr_model <- svm(y ~ x, data = train_svr)
  
  # Predict with SVR
  svr_pred <- predict(svr_model, test_svr)
  
  # Calculate the assessment indicators
  rmse_svr <- sqrt(mean((svr_pred - actual)^2))
  mae_svr <- mean(abs(svr_pred - actual))
  mape_svr <- mean(abs((svr_pred - actual) / actual)) * 100
  da_svr <- mean(sign(diff(svr_pred)) == sign(diff(actual)), na.rm = TRUE) * 100
  
  results <- rbind(results, data.frame(
    Model = "SVR",
    RMSE = rmse_svr,
    MAE = mae_svr,
    MAPE = mape_svr,
    DA = da_svr
  ))
}

```

```{r svr arima result, echo = TRUE, warning =FALSE}
summary_stats <- results %>%
  group_by(Model) %>%
  summarise(
    RMSE_mean = mean(RMSE), RMSE_sd = sd(RMSE), RMSE_min = min(RMSE), RMSE_max = max(RMSE),
    MAE_mean = mean(MAE), MAE_sd = sd(MAE), MAE_min = min(MAE), MAE_max = max(MAE),
    MAPE_mean = mean(MAPE), MAPE_sd = sd(MAPE), MAPE_min = min(MAPE), MAPE_max = max(MAPE),
    DA_mean = mean(DA), DA_sd = sd(DA), DA_min = min(DA), DA_max = max(DA)
  )

# Show the result
print(results)  
print(summary_stats)  
```

### 4.2. LSTM Using Historical Price Data

In this approach, the **LSTM model** is trained using only **historical Ethereum price data** to predict future prices. LSTM, or **Long Short-Term Memory**, is a type of recurrent neural network (RNN) that is well-suited for time series prediction due to its ability to capture long-term dependencies in sequential data. By utilizing past Ethereum prices, the model learns patterns and trends to predict future values.

### Model Setup:
- **Input**: Historical Ethereum prices (e.g., previous days' prices).
- **Goal**: To predict future Ethereum prices based on past price data alone.

This method relies purely on the price history, without incorporating external features, and is useful as a baseline for comparison with models using additional features.

### Python Implementation and Results:
The LSTM models were implemented in Python using **Keras** and **TensorFlow**. In here, I only show the result

```{r lstm old, echo = TRUE, warning =FALSE}
results_lstm <- data.frame(
  Metric = c("RMSE", "MAE", "MAPE", "DA"),
  Mean = c(1406.583845, 871.601923, 83.410101, 43.948919),
  Std = c(0.748246, 1.036438, 0.361255, 4.136689),
  Min = c(1405.648853, 870.345017, 83.022347, 37.524558),
  Max = c(1407.789478, 873.249721, 83.972149, 49.705305)
)

# Show the Result
print(results_lstm)
```


### 4.3. LSTM Using Selected Features

In this approach, the **LSTM model** is trained using the **selected features** identified during the feature selection stage. These features include economic and technological factors such as market cap, transaction fees, and currency exchange rates, which are believed to have an impact on Ethereum's price.

### Model Setup:
- **Input**: Selected features, including **marketcap**, **gas_limit**, **btc_price**, **eur_usd**, **Nasdaq**, and others.
- **Goal**: To predict Ethereum prices by incorporating both historical price data and external influencing factors.

This method aims to improve prediction accuracy by leveraging additional relevant factors beyond just the price, allowing the model to capture a broader range of influences on Ethereum's value.

##### Python Implementation and Results:
The LSTM models were implemented in Python using **Keras** and **TensorFlow**. In here, I only show the result

```{r lstm selected, echo = TRUE, warning =FALSE}
results_lstm_selected <- data.frame(
  Metric = c("RMSE", "MAE", "MAPE", "DA"),
  Mean = c(148.702267, 84.479687, 20.548105, 53.770833),
  Std = c(4.786485, 2.807826, 2.626956, 2.828444),
  Min = c(142.910592, 80.586956, 17.526311, 47.500000),
  Max = c(157.051510, 89.503912, 26.371179, 56.875000)
)

# Show the result
print(results_lstm_selected)
```

# 5. Result: Performance of Each model
### 5.1. Performance in terms of RMSE

The results show that the **LSTM model using selected features** outperforms other models in terms of **RMSE (Root Mean Squared Error)**. Specifically:

- **LSTM (selected_feature)**: RMSE_mean = **148.7023**
- **LSTM (old_price)**: RMSE_mean = **1406.5838**
- **SVR**: RMSE_mean = **232.9701**
- **ARIMA**: RMSE_mean = **1343.0943**

The **LSTM (selected_feature)** model achieves a significantly lower RMSE, indicating better prediction accuracy compared to both **LSTM (old_price)** and traditional models like **SVR** and **ARIMA**.

```{r rmse, echo = TRUE, warning =FALSE}
# Store RMSE
RMSE_table <- data.frame(
  Model = c("ARIMA", "SVR", "LSTM (old_price)", "LSTM (selected_feature)"),  
  RMSE_mean = c(
    summary_stats$RMSE_mean[summary_stats$Model == "ARIMA"],
    summary_stats$RMSE_mean[summary_stats$Model == "SVR"],
    1406.583845,  # RMSE_mean LSTM (old_price)
    148.702267    # RMSE_mean LSTM (selected_feature)
  ),
  RMSE_sd = c(
    summary_stats$RMSE_sd[summary_stats$Model == "ARIMA"], 
    summary_stats$RMSE_sd[summary_stats$Model == "SVR"], 
    0.748246,  # SD LSTM (old_price)
    4.786485   # SD LSTM (selected_feature)
  ),
  RMSE_min = c(
    summary_stats$RMSE_min[summary_stats$Model == "ARIMA"], 
    summary_stats$RMSE_min[summary_stats$Model == "SVR"], 
    1405.648853,  # RMSE_min LSTM (old_price)
    142.910592    # RMSE_min LSTM (selected_feature)
  ),
  RMSE_max = c(
    summary_stats$RMSE_max[summary_stats$Model == "ARIMA"], 
    summary_stats$RMSE_max[summary_stats$Model == "SVR"], 
    1407.789478,  # RMSE_max LSTM (old_price)
    157.051510    # RMSE_max LSTM (selected_feature)
  )
)

# Show the result
print(RMSE_table)

```

```{r rmse visualization, echo = TRUE, warning =FALSE}
# Table long format
RMSE_table_long <- gather(RMSE_table, key = "Metric", value = "Value", RMSE_mean, RMSE_sd, RMSE_min, RMSE_max)

# Bar
ggplot(RMSE_table_long, aes(x = Model, y = Value, fill = Metric)) +
  geom_bar(stat = "identity", position = "dodge") +
  theme_minimal() +
  labs(title = "Comparison of RMSE Metrics for Different Models",
       x = "Model",
       y = "RMSE Value") +
  scale_fill_manual(values = c("lightblue", "lightgreen", "lightcoral", "pink"))
```

### 5.2. Performance in terms of MAPE

The results show that the **LSTM model using selected features** also performs best in terms of **MAPE (Mean Absolute Percentage Error)**. Specifically:

- **LSTM (selected_feature)**: MAPE_mean = **20.5481**
- **LSTM (old_price)**: MAPE_mean = **83.4101**
- **SVR**: MAPE_mean = **178.6354**
- **ARIMA**: MAPE_mean = **2489.0273**

The **LSTM (selected_feature)** model achieves the lowest MAPE, indicating the best prediction accuracy in terms of percentage error compared to **LSTM (old_price)** and traditional models like **SVR** and **ARIMA**.

```{r mape, echo = TRUE, warning =FALSE}
# Store MAPE
MAPE_table <- data.frame(
  Model = c("ARIMA", "SVR", "LSTM (old_price)", "LSTM (selected_feature)"),  
  MAPE_mean = c(
    summary_stats$MAPE_mean[summary_stats$Model == "ARIMA"],
    summary_stats$MAPE_mean[summary_stats$Model == "SVR"],
    83.410101 ,  # MAPE_mean LSTM (old_price)
    20.548105     # MAPE_mean LSTM (selected_feature)
  ),
  MAPE_sd = c(
    summary_stats$MAPE_sd[summary_stats$Model == "ARIMA"], 
    summary_stats$MAPE_sd[summary_stats$Model == "SVR"], 
    0.361255,  # SD LSTM (old_price)
    2.626956   # SD LSTM (selected_feature)
  ),
  MAPE_min = c(
    summary_stats$MAPE_min[summary_stats$Model == "ARIMA"], 
    summary_stats$MAPE_min[summary_stats$Model == "SVR"], 
    83.022347,  # MAPE_min LSTM (old_price)
    17.526311    # MAPE_min LSTM (selected_feature)
  ),
  MAPE_max = c(
    summary_stats$MAPE_max[summary_stats$Model == "ARIMA"], 
    summary_stats$MAPE_max[summary_stats$Model == "SVR"], 
    83.972149,  # MAPE_max LSTM (old_price)
    26.371179    # MAPE_max LSTM (selected_feature)
  )
)

# Show the result
print(MAPE_table)
```

```{r mape visualization, echo = TRUE, warning =FALSE}
# Table long format
MAPE_table_long <- gather(MAPE_table, key = "Metric", value = "Value", MAPE_mean, MAPE_sd, MAPE_min, MAPE_max)

# Bar
ggplot(MAPE_table_long, aes(x = Model, y = Value, fill = Metric)) +
  geom_bar(stat = "identity", position = "dodge") +
  theme_minimal() +
  labs(title = "Comparison of MAPE Metrics for Different Models",
       x = "Model",
       y = "MAPE Value") +
  scale_fill_manual(values = c("lightblue", "lightgreen", "lightcoral", "pink"))
```

### 5.3. Performance in terms of MAE

The results show that the **LSTM model using selected features** also performs the best in terms of **MAE (Mean Absolute Error)**. Specifically:

- **LSTM (selected_feature)**: MAE_mean = **84.47969**
- **LSTM (old_price)**: MAE_mean = **871.60192**
- **SVR**: MAE_mean = **129.66815**
- **ARIMA**: MAE_mean = **1226.23994**

The **LSTM (selected_feature)** model achieves the lowest MAE, indicating that it makes the smallest average absolute error in predicting Ethereum prices compared to **LSTM (old_price)** and traditional models like **SVR** and **ARIMA**.

```{r mae, echo = TRUE, warning =FALSE}
# Store MAE
MAE_table <- data.frame(
  Model = c("ARIMA", "SVR", "LSTM (old_price)", "LSTM (selected_feature)"),  
  MAE_mean = c(
    summary_stats$MAE_mean[summary_stats$Model == "ARIMA"],
    summary_stats$MAE_mean[summary_stats$Model == "SVR"],
    871.60192,  # MAE_mean LSTM (old_price)
    84.479687   # MAE_mean LSTM (selected_feature)
  ),
  MAE_sd = c(
    summary_stats$MAE_sd[summary_stats$Model == "ARIMA"], 
    summary_stats$MAE_sd[summary_stats$Model == "SVR"], 
    1.036438,  # SD LSTM (old_price)
    2.807826   # SD LSTM (selected_feature)
  ),
  MAE_min = c(
    summary_stats$MAE_min[summary_stats$Model == "ARIMA"], 
    summary_stats$MAE_min[summary_stats$Model == "SVR"], 
    870.345017,  # MAE_min LSTM (old_price)
    80.586956    # MAE_min LSTM (selected_feature)
  ),
  MAE_max = c(
    summary_stats$MAE_max[summary_stats$Model == "ARIMA"], 
    summary_stats$MAE_max[summary_stats$Model == "SVR"], 
    873.249721,  # MAE_max LSTM (old_price)
    89.503912    # MAE_max LSTM (selected_feature)
  )
)

# Show the result
print(MAE_table)
```

```{r mae visualization, echo = TRUE, warning =FALSE}
# Table long format
MAE_table_long <- gather(MAE_table, key = "Metric", value = "Value", MAE_mean, MAE_sd, MAE_min, MAE_max)

# Bar
library(ggplot2)

ggplot(MAE_table_long, aes(x = Model, y = Value, fill = Metric)) +
  geom_bar(stat = "identity", position = "dodge") +
  theme_minimal() +
  labs(title = "Comparison of MAE Metrics for Different Models",
       x = "Model",
       y = "MAE Value") +
  scale_fill_manual(values = c("lightblue", "lightgreen", "lightcoral", "pink") + 
  theme(
    axis.text.x = element_text(size = 8))
```


### 5.4. Performance in terms of DA

The **LSTM model using selected features** performs similarly to **LSTM (old_price)** and **SVR** in terms of **DA (Directional Accuracy)**. Specifically:

- **LSTM (selected_feature)**: DA_mean = **53.77033**
- **LSTM (old_price)**: DA_mean = **43.94819**
- **SVR**: DA_mean = **53.64891**
- **ARIMA**: DA_mean = **0.1972387**

The **LSTM (selected_feature)** and **SVR** models achieve the highest **DA_mean**, indicating they are more accurate in predicting the correct direction of Ethereum price movements compared to **ARIMA**. The **LSTM (selected_feature)** model performs slightly better than **LSTM (old_price)** in terms of **DA**.


```{r da, echo = TRUE, warning =FALSE}
# Store DA
DA_table <- data.frame(
  Model = c("ARIMA", "SVR", "LSTM (old_price)", "LSTM (selected_feature)"),  
  DA_mean = c(
    summary_stats$DA_mean[summary_stats$Model == "ARIMA"],
    summary_stats$DA_mean[summary_stats$Model == "SVR"],
    43.948919,  # DA_mean LSTM (old_price)
    53.770833   # DA_mean LSTM (selected_feature)
  ),
  DA_sd = c(
    summary_stats$DA_sd[summary_stats$Model == "ARIMA"], 
    summary_stats$DA_sd[summary_stats$Model == "SVR"], 
    4.136689,  # SD LSTM (old_price)
    2.828444   # SD LSTM (selected_feature)
  ),
  DA_min = c(
    summary_stats$DA_min[summary_stats$Model == "ARIMA"], 
    summary_stats$DA_min[summary_stats$Model == "SVR"], 
    37.524558,  # DA_min LSTM (old_price)
    47.500000    # DA_min LSTM (selected_feature)
  ),
  DA_max = c(
    summary_stats$DA_max[summary_stats$Model == "ARIMA"], 
    summary_stats$DA_max[summary_stats$Model == "SVR"], 
    49.705305,  # DA_max LSTM (old_price)
    56.875000    # DA_max LSTM (selected_feature)
  )
)

# DA table
print(DA_table)
```

```{r da visualization, echo = TRUE, warning =FALSE}
# Table long format
DA_table_long <- gather(DA_table, key = "Metric", value = "Value", DA_mean, DA_sd, DA_min, DA_max)

# Bar chart
ggplot(DA_table_long, aes(x = Model, y = Value, fill = Metric)) +
  geom_bar(stat = "identity", position = "dodge") +
  theme_minimal() +
  labs(title = "Comparison of DA Metrics for Different Models",
       x = "Model",
       y = "DA Value") +
  scale_fill_manual(values = c("lightblue", "lightgreen", "lightcoral", "pink"))
```


# 6. Conclusion, Limitation and Future Work

### 6.1. Conclusion
This study successfully addressed all three main research questions:

- **Improved Prediction**: The LSTM model, when trained with economic and technological factors, significantly outperformed traditional models using historical exchange rate data alone (LSTM, SVR, and ARIMA). This confirms that incorporating diverse data sources improves prediction accuracy.

- **Key Factors**: The study identified **eight important economic and technological factors**—including **'marketcap'**, **'gas_limit'**, **'eur_usd'**, **'btc_price'**, **'blocksize'**, **'transaction_fee'**, **'Nasdaq'**, and **'cny_usd'**—that have a significant impact on Ethereum exchange rates.

- **Best Performing Model**: The **LSTM model (selected features)** outperformed **SVR** and **ARIMA** in terms of prediction accuracy, demonstrating its capability to handle complex relationships in time-series data.

This research successfully answers the key questions and demonstrates the importance of combining various data sources for more accurate Ethereum exchange rate predictions.

### 6.2. Limitations
Several limitations were identified:

- **Model Complexity**: LSTM models require significant data and careful tuning of architecture and hyperparameters.

- **Overfitting**: Despite using regularization techniques, there remains a risk of overfitting, requiring careful evaluation of generalization.

- **Non-stationarity**: Exchange rate data can be non-stationary, affecting prediction accuracy.

- **External Shocks**: Events like political or economic shifts can impact Ethereum exchange rates, which the model may not account for.

### 6.3. Future Research Prospects
Future research can focus on:

- **Adding More Variables**: Introducing additional economic and technological variables to improve predictions.

- **Exploring Other Models**: Testing models like **Transformer Networks** or hybrid models to compare performance.

- **Incorporating Market Sentiment**: Including market sentiment factors to enhance prediction accuracy.

- **Short-term and Long-term Models**: Developing models focused on different time horizons (e.g., daily, monthly).

For detailed results and methodology, please refer to the attached **PDF report**.

